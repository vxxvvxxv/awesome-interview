Полезные ссылки:
- [Go scheduler. Простыми словами](https://habr.com/ru/articles/743266/)
- [Dmitry Vyukov — Go scheduler: Implementing language with lightweight concurrency](https://www.youtube.com/watch?v=-K11rY57K7k)
- [Антон Сергеев, «Go под капотом»](https://www.youtube.com/watch?v=rloqQY9CT8I)
- [Планирование в Go: Часть I — Планировщик ОС](https://habr.com/ru/articles/478168/)
- [Планирование в Go: Часть II — Планировщик Go](https://habr.com/ru/articles/489862/)
- [Как устроен планировщик в Golang | Олег Козырев, Авито](https://www.youtube.com/watch?app=desktop&v=8z6FAaNPA-M)
- [Планировщик Go — самый подробный гайд простым языком](https://www.youtube.com/watch?v=kedW1xO3Zbo)

---

# Что такое Scheduler (планировщик)

**Scheduler** — это часть рантайма, которая управляет:

- созданием,
- планированием,
- переключением `goroutine` на потоки ОС (`M`),
- балансировкой нагрузки между ядрами (`P`)

| Что делает                          | Как работает                                                |
| ----------------------------------- | ----------------------------------------------------------- |
| Переключает goroutine               | С одного потока на другой при блокировках, ожиданиях и т.д. |
| Управляет `M` (OS thread), `P`, `G` | Использует модель `M:P:G`                                   |
| Ставит goroutine в очереди          | `runnable`, `waiting`, `syscall` и т.д.                     |
| Балансирует нагрузку                | Через work-stealing и локальные очереди                     |

Он **не занимается памятью или GC** — только исполнением кода.

# Модели многозадачности

| **Критерий**             | **Кооперативная**             | **Вытесняющая**                         |
| ------------------------ | ----------------------------- | --------------------------------------- |
| **Управление задачами**  | Задачи сами отдают управление | Планировщик принудительно останавливает |
| **Стабильность**         | Низкая (зависание возможно)   | Высокая                                 |
| **Накладные расходы**    | Низкие                        | Высокие                                 |
| **Сложность реализации** | Простая                       | Сложная                                 |
| **Примеры**              | Windows 3.x, DOS-приложения   | Linux, Windows 10, iOS                  |
| **Использование**        | Встроенные системы, старые ОС | Современные ОС, серверы, игры           |

## Кооперативная

Задачи (процессы/потоки) **добровольно передают управление** планировщику, например, через вызов `yield()`. Пока задача не отдаст управление, другие задачи не выполняются.

### Плюсы

- **Низкие накладные расходы**:
	- Переключение контекста происходит только в точках явного «отпускания» управления.
	- Пример: В играх 90-х (например, _SimCity_) задачи обновления графики и физики переключались быстро, так как код был оптимизирован.
- **Простота реализации**:
	- Не требуется сложный планировщик.
	- Пример: Ранние версии Windows (3.x) использовали кооперативную многозадачность для приложений.
- **Предсказуемость**:
	- Программист точно знает, когда произойдет переключение.
	- Пример: Встроенные системы с жесткими временными ограничениями.

### Минусы

- **Риск зависания системы**:
	- Если задача не вызывает `yield()`, система блокируется.
	- Пример: В Windows 3.x зависшее приложение «замораживало» весь компьютер.
- **Несправедливое распределение ресурсов**:
	- Одна «жадная» задача может монополизировать процессор.
	- Пример: Долгие вычисления в фоновом потоке без `yield()` блокируют интерфейс.
- **Сложность отладки**:
	- Ошибки в одной задаче влияют на всю систему.

### Примеры использования

- **Игры и приложения реального времени**:
	- Где требуется полный контроль над выполнением кода (например, _DOOM_ на MS-DOS).
- **Микроконтроллеры**:
	- Системы без ОС, где задачи работают в бесконечном цикле с ручным управлением.

## Вытесняющая

Планировщик **принудительно останавливает задачи** через определенные интервалы времени или приоритеты, не дожидаясь их согласия.

### Плюсы

- **Стабильность**:
	- Даже «зависшая» задача не блокирует систему.
	- Пример: Современные ОС (Linux, Windows) не зависают из-за одного приложения.
- **Справедливое распределение ресурсов**:
	- Планировщик гарантирует, что все задачи получат процессорное время.
	- Пример: Серверы, где важно обслуживать множество клиентов одновременно.
- **Изоляция задач**:
	- Ошибки в одной задаче не влияют на другие.

### Минусы

- **Высокие накладные расходы**:
	- Частые переключения контекста требуют ресурсов.
	- Пример: В реальном времени (например, робототехника) это может приводить к задержкам.
- **Сложность синхронизации**:
	- Нужны механизмы блокировок (мьютексы, семафоры) для защиты общих данных.
	- Пример: Race conditions в многопоточных приложениях.
- **Непредсказуемость**:
	- Программист не контролирует момент переключения задач.

### Примеры использования

- **Современные операционные системы**:
	- Windows, Linux, macOS — все используют вытесняющую многозадачность.
- **Серверные приложения**:
	- Веб-серверы (например, Nginx) обрабатывают тысячи соединений параллельно.
- **Игры с многопоточностью**:
	- Распределение рендеринга, физики и AI по разным потокам.

## Модель многозадачности в Go

Полезные ссылки:
- [GO Scheduler: теперь не кооперативный?](https://habr.com/ru/articles/502506/)

В Go используется **гибридный подход**:

- **Кооперативные элементы**: Горутины могут добровольно отдавать управление через `runtime.Gosched()`.
- **Вытеснение**:
	- Горутины автоматически вытесняются при блокировке (каналы, I/O).
    - Начиная с Go 1.14, горутины **"в аварийном режиме"** вытесняются асинхронно (на основе прерываний).

### Пример

```go
// Кооперативное переключение
go func() {
    for {
        // Долгие вычисления
        runtime.Gosched() // Явное освобождение CPU
    }
}()

// Вытеснение при блокировке
go func() {
    data := <-ch // Блокировка → планировщик переключается на другую горутину
}()
```

# Что такое GMP-модель?

Полезные ссылки:
- [Analysis of Golang GPM Models](https://www.sobyte.net/post/2022-07/go-gmp/#2-life-cycle-of-m)

**GMP** — это архитектура планировщика Go, которая управляет горутинами, потоками ОС и распределением ресурсов. Она обеспечивает высокую производительность и эффективную конкурентность.

## Что означает каждая буква?

### Коротко

- **G** — ваши горутины.
- **M** — потоки ОС, которые выполняют код.
- **P** — логические процессоры, которые распределяют **G** между **M**.

### Детальнее

| Компонент | Описание                                                                                                                                                                                                                                                                                                                                                                    |
| --------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **G**     | **Goroutine** — горутины, легковесная «нить» выполнения. Не поток ОС, а абстракция Go, требующая минимум ресурсов (2 КБ стека на старте, динамически растёт).<br><br>На каждом **P** должна выполняться **G** и scheduler за этим следит.                                                                                                                                   |
| **M**     | **Machine (OS Thread)** — поток операционной системы. Именно **M** выполняет код горутин. Каждый **M** привязан к ядру CPU.<br>Каждый **P** работает на потоке из **M**. <br><br>Заметьте, что **P** не всегда равно **M**, например, поток может быть заблокирован `syscall`'ом и тогда для его **P** будет выделен другой поток. А еще есть CGO и прочие и прочие нюансы. |
| **P**     | **Processor (логический процессор)** — виртуальный ресурс, который управляет очередями горутин и связывает **M** с **G**. Количество **P** равно `GOMAXPROCS`  (их количество мы можем поменять функцией `runtime.GOMAXPROCS`, по умолчанию — число ядер CPU).<br><br>На каждом логическом процессоре в один момент времени может независимо выполняться одна горутина.     |

## Как взаимодействуют между собой?

### Базовая схема работы

1. **P** создается в количестве `GOMAXPROCS` (например, 4 для 4-ядерного CPU).
2. Каждый **P** имеет локальную очередь (**local runqueue**) горутин (**G**), готовых к выполнению.
3. **M** (поток ОС) «цепляется» к **P** и выполняет горутины из его очереди.
4. Если локальная очередь **P** пуста, он «крадет» горутины из очереди другого **P** (**work-stealing**).

#### Пример

```go
func main() {
    go task1() // G1 создается и попадает в очередь P1
    go task2() // G2 попадает в очередь P1
    time.Sleep(time.Second)
}

func task1() { /*...*/ } // G1
func task2() { /*...*/ } // G2
```

1. При старте программы создаются **P1**, **P2**, ..., **Pn** (по количеству ядер).
2. **M1** (поток ОС) связывается с **P1** и начинает выполнять горутины из его очереди.
3. Если **G1** блокируется (например, на I/O), **M1** отсоединяется от **P1**, чтобы не простаивать, и создает новый поток **M2** для обработки других горутин.

### Динамическое взаимодействие компонентов

#### Блокировка горутины (например, вызов time.Sleep, I/O)

1. **G** (например, `G1`) блокируется.
2. **M1** отсоединяется от **P1** и освобождает поток ОС.
3. **P1** переключается на другую горутину (`G2`) из своей очереди.
4. Когда `G1` разблокируется, она возвращается в очередь **P1** (или другого **P**).

#### Системный вызов (например, работа с файлом)

1. **G** выполняет блокирующий системный вызов.
2. Планировщик Go создает новый **M** (поток ОС), чтобы не терять ресурсы **P**.
3. После завершения системного вызова **G** возвращается в очередь.

#### Каналы (channels) и синхронизация

- Если **G** ожидает данные из канала, она переходит в режим ожидания и освобождает **M**, который может выполнять другие **G**.

## Преимущества GMP-модели

- **Масштабируемость**:
	- Тысячи горутин работают на небольшом числе потоков ОС.
- **Эффективность CPU**:
	- **P** и work-stealing минимизируют простои потоков.
- **Низкие накладные расходы**:
	- Переключение горутин происходит в пространстве пользователя, без участия ядра ОС.

## Пример: Как GMP обрабатывает 10 000 горутин

1. Создаются 10 000 **G** (горутин).
2. Они распределяются по локальным очередям **P** (например, 4 **P** для 4 ядер).
3. Каждый **M** (поток ОС) выполняет горутины из очереди своего **P**.
4. Если одна **G** блокируется, **M** не простаивает — переключается на другую **G**.

# Очереди

Когда мы запускаем `go func()`, создаётся новая `goroutine`, которую нужно **выполнить**. Эти горутины ставятся в специальные **очереди задач**, с которыми работает планировщик.

## Что такое локальная очередь?

- У каждого **`P` (Processor)** в планировщике есть **своя локальная очередь** (`runq`).
- Хранит `goroutine`, готовые к исполнению.
- Очень **быстрая**, работает без глобальных блокировок.
- Размер очереди ограничен (обычно ~256 задач).

## Что такое глобальная очередь?

- **Одна на весь рантайм** (`sched.runq`).
- Используется как **резервное хранилище**, когда локальные очереди переполнены или пусты.
- Защищена глобальной блокировкой, доступ медленнее.
- При старте `goroutine`, она **может попасть** либо в локальную очередь, либо в глобальную.

## Когда задачи переходят между очередями?

### Локальная → Глобальная

- Когда **локальная очередь заполнена**, лишние `goroutine` сбрасываются в глобальную.
- Или при **создании горутины**, если локальная очередь не может принять её.

### Глобальная → Локальная

Когда **локальная очередь пуста**, `P` может взять несколько задач из глобальной (обычно _batch_ из 1–61).

## Кто работает с очередями?

- **Каждый `P`** (Processor) управляет своей локальной очередью.
- **Планировщик Go** решает:
    - Когда взять задачи из глобальной очереди.
    - Когда делать **work stealing** (см. ниже).
    - Когда запускать / блокировать потоки (`M`).

## Какие правила установлены разработчиками Go?

- **По возможности использовать локальные очереди** — они быстрые, минимизируют блокировки.
- **Ограничить размер локальных очередей** — чтобы не захламлялись.
- **Периодически сбрасывать в глобальную очередь** — для справедливости.
- **Если локально нечего делать — делать work stealing** (воровать работу у других `P`).

## Что такое **work-stealing**

**Work Stealing** — это стратегия, при которой **`P`, у которого нет задач, "ворует" задачи у других `P`**, у которых они есть.

- Работает эффективно, потому что:
    - Не требует координации (каждый сам себе вор).
    - Балансирует нагрузку динамически.
    - Меньше блокировок, чем при совместном доступе к общей очереди.

В Go, воруют **половину** задач из локальной очереди другого `P`.

## Что такое **work-sharing**

**Work-sharing** — это стратегия планирования задач, при которой **новые задачи активно распределяются** между исполнителями (потоками, процессами) **в момент их создания**.

То есть, **автор задачи сам решает, кому её "отдать"**.

### Как это работает?

- Когда создаётся новая задача (например, `goroutine`, поток, или таска), текущий исполнитель **пытается немедленно отдать её** какому-то другому исполнителю.
- Это распределение может происходить:
    - **по кругу** (round-robin),
    - по текущей загрузке (если замеряется),
    - случайным образом,
    - в очередь общего доступа.

## Пример work-sharing

Представь, что у нас 4 потока, и один из них создаёт 10 задач. Он тут же пытается:
- Задачу 1 отдать потоку 2
- Задачу 2 отдать потоку 3
- Задачу 3 — потоку 4
- и т.д.

## Примеры использования work-sharing:

- Старые версии OpenMP
- Некоторые реализации thread pools
- MPI (в параллельных вычислениях)
- Старая модель планировщика ОС (раньше в Linux)

### Недостатки work-sharing

1. **Централизация** — планирование задач происходит **при создании**, что создаёт **узкое место**.
2. **Оверхед на синхронизацию** — приходится обращаться к другим потокам/очередям.
3. **Неустойчивая балансировка** — если один поток создал много задач, но отдать их не успел — **другие простаивают**.
4. **Невозможно предсказать нагрузку** — задача может быть короткой или тяжёлой, но уже распределена.

### Когда хорошо работает

- Когда **все задачи примерно равны по весу**.
- Когда **создание задач — редкость**, и важнее моментальная передача.
- Когда нужно **строго контролировать, где что выполняется** (например, привязка к NUMA-узлу, CPU и т.д.)

## Почему в Go **work-stealing**, а не **work-sharing**

| Характеристика          | Work-sharing 🧺            | Work-stealing 🕵️‍♂️     |
| ----------------------- | -------------------------- | ------------------------ |
| Кто распределяет задачи | Тот, кто создаёт задачу    | Тот, кто **ищет** задачу |
| Когда распределяется    | При создании               | При простое исполнителя  |
| Масштабируемость        | Ограниченная (узкое место) | Отличная                 |
| Балансировка нагрузки   | Не всегда эффективна       | Динамическая, адаптивная |

- Потому что Go активно использует **конкурентность** и **масштабируемость**.
- `goroutine` может создаваться **внутри цикла**, тысячи раз в секунду.
- Делегировать каждую задачу вручную = блокировки, т.е. медленно.
- Вместо этого:
    - Задача **кладётся в локальную очередь**, и если кто-то простаивает — он сам её **украдёт** (work-stealing).

Поэтому **Go использует work-stealing** — это **lock-free** и **максимально эффективное распределение нагрузки** в многопоточном окружении.

## В какой момент goroutine переключаются?

**Goroutine переключаются не "в любое время", а в строго определённых точках**, которые определяются самим рантаймом. Это **кооперативная многозадачность**, а не принудительная, как в некоторых других языках.

### Примеры

**Основные моменты**, когда планировщик Go может **переключить выполнение на другую горутину**:

### Системные вызовы / блокирующие операции

Если `goroutine` делает что-то, что **может блокироваться** (например, I/O, ожидание канала, `select`, `time.Sleep`, `sync.Mutex.Lock`, `cond.Wait` и т.д.), она **переходит в состояние ожидания**, и планировщик запускает другую.

```go
<-ch         // блокирующий recv
ch <- value  // блокирующий send
```

### Ручной `runtime.Gosched()`

Позволяет **добровольно уступить** управление другой `goroutine`.

```go
runtime.Gosched()
```

### Внутри функции с `channel`, `select`, `lock` или `time.Sleep` 

Go знает, что они могут привести к ожиданию → возможно переключение.

### Создание новой `goroutine`

Когда ты вызываешь `go f()`, планировщик **может немедленно переключиться** на неё (но не обязан).

### Периодические прерывания планировщика (preemption)

Начиная с Go 1.14, появилась **асинхронная предвыборка**:

> Даже если `goroutine` "занята бесконечным циклом", она **может быть принудительно остановлена**.

Это работает примерно раз в 10мс, и **вставляет "точку прерывания"** в безопасном месте (например, в вызов функции).

Например:

```go
for {
    x++
}
```

В старых версиях Go это могло **намертво занять CPU**. Сейчас — нет, планировщик умеет **прерывать "жадную" горутину**.

### При выполнении `function calls`

Go вставляет **"точки прерывания"** перед вызовами функций, особенно если включен флаг компиляции `preemptible`.

### Сборщик мусора (GC)

Во время **стоп-мир** фазы (короткой), планировщик может тоже поменять текущую горутину.

## Как Go решает, кого переключить?

- Планировщик проверяет, есть ли другие `goroutine`, готовые к запуску (`runnable`).
- Если текущая блокируется или явно уступила (`Gosched`), выбирается следующая.
- Если нет, текущая продолжает работать.


Например, когда `G` блокируется, `M` может либо:
- Вернуть `P` в пул (и подцепить другой `G`),
- Либо сам уйти в сон, если нет задач.

| Событие                 | Возможность переключения      |
| ----------------------- | ----------------------------- |
| Блокировка на канале    | ✅ Да                          |
| `select`                | ✅ Да                          |
| `time.Sleep`, `sync`    | ✅ Да                          |
| `runtime.Gosched()`     | ✅ Да                          |
| Вызов функции (иногда)  | ✅ Да (точка прерывания)       |
| Долгий цикл без вызовов | ❌ (до Go 1.14), ✅ (сейчас)    |
| Новый `go func()`       | ⚠️ Возможно, не гарантировано |

# Что такое netpoller

[Source code](https://github.com/golang/go/blob/master/src/runtime/netpoll.go)

`netpoller` — это компонент Go-рантайма, который занимается **асинхронным ожиданием сетевых (и других) событий**, таких как:

- сокет стал доступен для чтения или записи
- произошёл таймаут
- соединение закрыто и т.д.

Он используется, чтобы **не блокировать** goroutine, которые ждут ответа по сети, и **переводить их в спящий режим**, пока данные не готовы.

## Как работает

- Go использует системные механизмы:
    - `epoll` (Linux)
    - `kqueue` (macOS/BSD)
    - `IOCP` (Windows)
1. Когда goroutine вызывает `net.Conn.Read()` или `Write()` — она **не блокируется на системный вызов напрямую**.
2. Вместо этого:
    - создаётся **ждущая запись (pollDesc)**, привязанная к сокету
    - goroutine **отправляется в сон**
3. Когда сокет готов (например, можно читать):
    - netpoller получает событие от ОС
    - поднимает goroutine обратно в планировщик (`runnable`)

Всё это **экономит потоки ОС**, и делает сетевые операции **масштабируемыми**.

### Какую роль играет

Нужен, чтобы:

- Не блокировать goroutine при работе с сетью
- Уметь "спать" и "просыпаться", когда сокет готов
- Работать с тысячами соединений одновременно

## Что такое **ждущая запись (pollDesc)**

`pollDesc` — это **структура, которую рантайм Go привязывает к дескриптору файла/сокета** (FD), чтобы управлять ожиданием сетевых событий.

Она содержит:

- Флаги (можно ли читать/писать)
- Указатель на связанную `goroutine`    
- Информацию для пробуждения
- Таймауты

### Когда создаётся `pollDesc`

- При вызове `net.Dial`, `net.Listen`, `conn.Read()`, `conn.Write()` и т.д.
- Go регистрирует FD в `netpoller` (например через `epoll_ctl` на Linux)
- Создаёт `pollDesc`, чтобы:
    - “парковать” goroutine
    - и “разбудить”, когда ОС скажет: "готово"

### Визуально

```go
Goroutine (G)
   │
   ▼
net.Conn.Read()
   │
   ▼
create pollDesc ───▶ register in epoll/kqueue
   │
   ▼
runtime.park() → G status = waiting
```

Когда ОС сообщает: “можно читать”, то **netpoller**:

```go
→ pollDesc готов
→ связанная goroutine становится runnable
→ возвращается в планировщик
```

## Что происходит с goroutine, когда она отправляет запрос по сети

Если вызываем:

```go
resp, err := http.Get("http://example.com")
```

Тогда:

1. Запрос уходит в сеть, goroutine вызывает `netpoll`
2. Goroutine **“паркуется”** (приостанавливается, снимается с `P`)
3. Когда данные пришли, netpoll **будит goroutine** и она продолжает выполнение

**Важно**: один поток может обрабатывать тысячи goroutine благодаря netpoll'у

## Пример

Код для наблюдения:

```go
package main

import (
    "fmt"
    "net"
    "time"
)

func main() {
    go func() {
        conn, _ := net.Dial("tcp", "example.com:80")
        fmt.Println("connected", conn != nil)
    }()
    time.Sleep(time.Second * 2)
}
```

Необходимо добавить при запуске  `GODEBUG=netpoll=1,schedtrace=1000` — тогда можно в логах, как netpoll и sysmon работают.

# Что такое sysmon?

`sysmon` (System Monitor) — это **фоновый поток рантайма Go**, выполняет системный мониторинг и работает как "смотритель" за всей системой рантайма.

### Какую роль играет?

Выполняет несколько важных задач:

1. **Отслеживает спящие goroutine, ожидающие syscall**    
2. **Следит за блокировками и зависшими потоками**
3. **Рестартует netpoller при необходимости**
4. **Проверяет таймауты (`time.Sleep`, `Timer`)**
5. **Запускает GC при необходимости**
6. **Делает preemption (прерывание долгоживущих goroutine)**

Также он:

- **будит goroutine**, если syscall закончился
- **делает preemption** (если одна goroutine "залипла" и мешает другим)

# Что происходит при `syscall`?

[Source code](https://github.com/golang/go/tree/master/src/syscall)

Когда goroutine вызывает **системный вызов**, например:
```go
os.Open("file.txt") // может вызвать блокирующий syscall
```

1. **Syscall может заблокировать поток ОС (M)**
2. Go **пытается распознать** это:
    - Если вызов быстрый — всё ок
    - Если **задержка >10μs**, sysmon понимает: M блокирован
3. Тогда:
    - Goroutine, которая вызвала `syscall`, остаётся заблокированной
    - Но Go создаёт **новый M**, чтобы не простаивал `P`
    - Другие goroutine продолжают выполняться
